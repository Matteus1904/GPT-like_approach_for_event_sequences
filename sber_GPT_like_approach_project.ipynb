{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8a795c70",
      "metadata": {
        "id": "8a795c70"
      },
      "source": [
        "# Colab setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8b6cedd5",
      "metadata": {
        "id": "8b6cedd5"
      },
      "outputs": [],
      "source": [
        "# if 'google.colab' in str(get_ipython()):\n",
        "#     !pip install pytorch-lifestream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "Em3-s0dLH5zB",
      "metadata": {
        "id": "Em3-s0dLH5zB"
      },
      "outputs": [],
      "source": [
        "# !pip install lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7431993",
      "metadata": {
        "id": "a7431993"
      },
      "source": [
        "## Data load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "86d984d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# if not os.path.exists('data/rosbank/train.csv'):\n",
        "#     !mkdir -p data/rosbank\n",
        "#     !curl -OL https://storage.yandexcloud.net/di-datasets/rosbank-ml-contest-boosters.pro.zip\n",
        "#     !unzip -j -o rosbank-ml-contest-boosters.pro.zip 'data/*.csv' -d data/rosbank\n",
        "#     !mv age-prediction-nti-sbebank-2019.zip data/rosbank/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e91a902",
      "metadata": {
        "id": "9e91a902"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "587df1ea",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-04T18:11:04.590559Z",
          "iopub.status.busy": "2022-05-04T18:11:04.590097Z",
          "iopub.status.idle": "2022-05-04T18:11:06.256016Z",
          "shell.execute_reply": "2022-05-04T18:11:06.255464Z"
        },
        "id": "587df1ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/matvey/.pyenv/versions/3.9.16/envs/ML_project/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from models import GptPretrainContrastiveModule, NextItemPredictionModule\n",
        "\n",
        "from ptls.nn import TrxEncoder, RnnEncoder\n",
        "from ptls.frames.gpt import GptPretrainModule, GptDataset\n",
        "from ptls.preprocessing import PandasDataPreprocessor\n",
        "from ptls.data_load.datasets import MemoryMapDataset\n",
        "from ptls.data_load.iterable_processing import SeqLenFilter\n",
        "from ptls.frames import PtlsDataModule\n",
        "\n",
        "from dataset import MlmNoSliceDataset\n",
        "\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82f989bc",
      "metadata": {
        "id": "82f989bc"
      },
      "source": [
        "## Data preproccessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8cf63640",
      "metadata": {},
      "outputs": [],
      "source": [
        "source_data = pd.read_csv('transactions_sber.csv')\n",
        "source_data = source_data.rename({'trans_date': 'TRDATETIME'}, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8e45e574",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>TRDATETIME</th>\n",
              "      <th>small_group</th>\n",
              "      <th>amount_rur</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33172</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>71.463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33172</td>\n",
              "      <td>6</td>\n",
              "      <td>35</td>\n",
              "      <td>45.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33172</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>13.887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33172</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>15.983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33172</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>21.341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26450572</th>\n",
              "      <td>43300</td>\n",
              "      <td>727</td>\n",
              "      <td>25</td>\n",
              "      <td>7.602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26450573</th>\n",
              "      <td>43300</td>\n",
              "      <td>727</td>\n",
              "      <td>15</td>\n",
              "      <td>3.709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26450574</th>\n",
              "      <td>43300</td>\n",
              "      <td>727</td>\n",
              "      <td>1</td>\n",
              "      <td>6.448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26450575</th>\n",
              "      <td>43300</td>\n",
              "      <td>727</td>\n",
              "      <td>11</td>\n",
              "      <td>24.669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26450576</th>\n",
              "      <td>43300</td>\n",
              "      <td>729</td>\n",
              "      <td>3</td>\n",
              "      <td>19.408</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26450577 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          client_id  TRDATETIME  small_group  amount_rur\n",
              "0             33172           6            4      71.463\n",
              "1             33172           6           35      45.017\n",
              "2             33172           8           11      13.887\n",
              "3             33172           9           11      15.983\n",
              "4             33172          10           11      21.341\n",
              "...             ...         ...          ...         ...\n",
              "26450572      43300         727           25       7.602\n",
              "26450573      43300         727           15       3.709\n",
              "26450574      43300         727            1       6.448\n",
              "26450575      43300         727           11      24.669\n",
              "26450576      43300         729            3      19.408\n",
              "\n",
              "[26450577 rows x 4 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "source_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7e06bd27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "execution": {
          "iopub.execute_input": "2022-05-04T18:11:06.260046Z",
          "iopub.status.busy": "2022-05-04T18:11:06.259544Z",
          "iopub.status.idle": "2022-05-04T18:11:12.319460Z",
          "shell.execute_reply": "2022-05-04T18:11:12.317693Z"
        },
        "id": "7e06bd27",
        "outputId": "b070264a-4f29-4087-9214-6f5bf34af76f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>TRDATETIME</th>\n",
              "      <th>small_group</th>\n",
              "      <th>amount_rur</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5201569</th>\n",
              "      <td>44379</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>62.535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2788175</th>\n",
              "      <td>43594</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>10.524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2788174</th>\n",
              "      <td>43594</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>86.255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18975203</th>\n",
              "      <td>5882</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>5.132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18975202</th>\n",
              "      <td>5882</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>11.678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          client_id  TRDATETIME  small_group  amount_rur\n",
              "5201569       44379           0           52      62.535\n",
              "2788175       43594           0          125      10.524\n",
              "2788174       43594           0           36      86.255\n",
              "18975203       5882           0           12       5.132\n",
              "18975202       5882           0           18      11.678"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# data_path = 'data/rosbank'\n",
        "\n",
        "\n",
        "# source_data = pd.read_csv('transactions_sber.csv')\n",
        "# # source_data['TRDATETIME'] = pd.to_datetime(source_data['TRDATETIME'], format='%d%b%y:%H:%M:%S')\n",
        "source_data = source_data.sort_values(by=['TRDATETIME'])\n",
        "source_data = source_data.rename(columns={'cl_id':'client_id', 'MCC':'small_group', 'amount':'amount_rur'})\n",
        "source_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6735f933",
      "metadata": {},
      "outputs": [],
      "source": [
        "mcc_to_id = {mcc: i+1 for i, mcc in enumerate(source_data['small_group'].unique())}\n",
        "\n",
        "source_data['amount_rur_bin'] = 1 + KBinsDiscretizer(10, encode='ordinal', subsample=None).fit_transform(source_data[['amount_rur']]).astype('int')\n",
        "source_data['small_group'] = source_data['small_group'].map(mcc_to_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8615b722",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-04T18:11:12.324005Z",
          "iopub.status.busy": "2022-05-04T18:11:12.323387Z",
          "iopub.status.idle": "2022-05-04T18:11:12.376973Z",
          "shell.execute_reply": "2022-05-04T18:11:12.376546Z"
        },
        "id": "8615b722"
      },
      "outputs": [],
      "source": [
        "preprocessor = PandasDataPreprocessor(\n",
        "    col_id='client_id',\n",
        "    col_event_time='TRDATETIME',\n",
        "    event_time_transformation='dt_to_timestamp',\n",
        "    cols_category=['small_group'],\n",
        "    cols_numerical=['amount_rur_bin'],\n",
        "    return_records=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fca72f6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-05-04T18:11:12.380482Z",
          "iopub.status.busy": "2022-05-04T18:11:12.380011Z",
          "iopub.status.idle": "2022-05-04T18:12:29.766372Z",
          "shell.execute_reply": "2022-05-04T18:12:29.766793Z"
        },
        "id": "fca72f6e",
        "outputId": "725b7379-aa49-4fc5-8a41-ca8979888ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 30.1 s, sys: 3.74 s, total: 33.8 s\n",
            "Wall time: 33.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "dataset = preprocessor.fit_transform(source_data[['client_id', 'TRDATETIME', 'small_group', 'amount_rur_bin']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0e4ca12d",
      "metadata": {
        "id": "0e4ca12d"
      },
      "outputs": [],
      "source": [
        "dataset = sorted(dataset, key=lambda x: x['client_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "98e7d39d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-05-04T18:12:29.770820Z",
          "iopub.status.busy": "2022-05-04T18:12:29.770330Z",
          "iopub.status.idle": "2022-05-04T18:12:30.164858Z",
          "shell.execute_reply": "2022-05-04T18:12:30.165297Z"
        },
        "id": "98e7d39d",
        "outputId": "85da48c1-2992-4a08-e89e-68dda424f8d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19200, 4800, 6000)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_valid, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "train, valid = train_test_split(train_valid, test_size=0.2, random_state=42)\n",
        "len(train), len(valid), len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5af110e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5af110e1",
        "outputId": "698da14d-523c-4326-faf5-1640c4b75664"
      },
      "outputs": [],
      "source": [
        "train_dl = PtlsDataModule(\n",
        "    train_data=GptDataset(\n",
        "        MemoryMapDataset(\n",
        "            data=train,\n",
        "            # i_filters=[\n",
        "            #     SeqLenFilter(min_seq_len=25),\n",
        "            # ],\n",
        "        ),\n",
        "        min_len=25, \n",
        "        max_len=200\n",
        "    ),\n",
        "    valid_data=MlmNoSliceDataset(\n",
        "        MemoryMapDataset(\n",
        "            data=valid,\n",
        "            # i_filters=[\n",
        "            #     SeqLenFilter(min_seq_len=25),\n",
        "            # ],\n",
        "        ),\n",
        "    ),\n",
        "    test_data=MlmNoSliceDataset(\n",
        "        MemoryMapDataset(\n",
        "            data=test,\n",
        "            # i_filters=[\n",
        "            #     SeqLenFilter(min_seq_len=25),\n",
        "            # ],\n",
        "        ),\n",
        "    ),\n",
        "    train_batch_size=128,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f9080a6f",
      "metadata": {
        "id": "f9080a6f"
      },
      "source": [
        "## Embedding training (representation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56493c0b",
      "metadata": {
        "id": "56493c0b"
      },
      "source": [
        "Model training in our framework organised via pytorch-lightning (pl) framework.\n",
        "The key parts of neural networks training in pl are: \n",
        "\n",
        "    * model (`pytorch_lightning.LightningModule`)\n",
        "    * data loader (`torch.utils.data.DataLoader`)\n",
        "    * trainer (`pytorch_lightning.Trainer`)\n",
        "    \n",
        "For futher details check https://pytorchlightning.ai/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "Mly1BWDITvF-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mly1BWDITvF-",
        "outputId": "0b640b0e-d5d3-499b-e822-740f5d2af498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique MCC codes: 202\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of unique MCC codes:\", source_data['small_group'].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43a6ee58",
      "metadata": {
        "id": "43a6ee58"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "61ead7d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "trx_encoder_params = dict(\n",
        "    embeddings_noise=0.0,\n",
        "    embeddings={\n",
        "        'small_group': {'in': 350, 'out': 16},\n",
        "        'amount_rur_bin':{'in': 60, 'out': 16}\n",
        "    },\n",
        ")\n",
        "\n",
        "seq_encoder = RnnEncoder(\n",
        "        input_size=32,\n",
        "        hidden_size=32,\n",
        "        type='gru',\n",
        ")\n",
        "\n",
        "model = GptPretrainModule(\n",
        "    trx_encoder=TrxEncoder(**trx_encoder_params),\n",
        "    seq_encoder=seq_encoder,\n",
        "    max_lr=0.1\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8135513b",
      "metadata": {},
      "source": [
        "### Pre-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b22b6b2a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "trainer = pl.Trainer(\n",
        "    max_epochs=100,\n",
        "    gpus=1 if torch.cuda.is_available() else 0,\n",
        "    callbacks=[pl.callbacks.EarlyStopping('gpt/valid_gpt_loss')],\n",
        "    enable_progress_bar=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ef1e4af6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logger.version = 52\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name           | Type             | Params\n",
            "----------------------------------------------------\n",
            "0 | trx_encoder    | TrxEncoder       | 6.6 K \n",
            "1 | _seq_encoder   | RnnEncoder       | 6.4 K \n",
            "2 | head           | ModuleDict       | 30.9 K\n",
            "3 | loss           | CrossEntropyLoss | 0     \n",
            "4 | train_gpt_loss | MeanMetric       | 0     \n",
            "5 | valid_gpt_loss | MeanMetric       | 0     \n",
            "----------------------------------------------------\n",
            "43.8 K    Trainable params\n",
            "0         Non-trainable params\n",
            "43.8 K    Total params\n",
            "0.175     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/matvey/.pyenv/versions/3.9.16/envs/ML_project/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                           "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/matvey/.pyenv/versions/3.9.16/envs/ML_project/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20: 100%|██████████| 188/188 [00:04<00:00, 45.15it/s, loss=4.72, v_num=52, gpt/valid_gpt_loss=4.670]\n",
            "{'gpt/loss': tensor(4.7345), 'gpt/valid_gpt_loss': tensor(4.6724), 'gpt/train_gpt_loss': tensor(4.7042)}\n",
            "CPU times: user 2min 5s, sys: 8.82 s, total: 2min 14s\n",
            "Wall time: 1min 31s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(f'logger.version = {trainer.logger.version}')\n",
        "trainer.fit(model, train_dl)\n",
        "print(trainer.logged_metrics)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c3b2d4fe",
      "metadata": {},
      "source": [
        "### Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "98379275",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_downstream = NextItemPredictionModule(\n",
        "    trx_encoder=TrxEncoder(**trx_encoder_params), # model.trx_encoder,\n",
        "    seq_encoder=seq_encoder, # model._seq_encoder,\n",
        "    target_col='small_group',\n",
        "    max_lr=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f729fd2e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "trainer = pl.Trainer(\n",
        "    max_epochs=100,\n",
        "    gpus=1 if torch.cuda.is_available() else 0,\n",
        "    callbacks=[pl.callbacks.EarlyStopping('gpt/valid_f1_weighted', patience=5, mode='max')],\n",
        "    enable_progress_bar=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "98dd6c5b",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name           | Type             | Params\n",
            "----------------------------------------------------\n",
            "0 | trx_encoder    | TrxEncoder       | 6.6 K \n",
            "1 | _seq_encoder   | RnnEncoder       | 6.4 K \n",
            "2 | head           | Head             | 24.9 K\n",
            "3 | loss           | CrossEntropyLoss | 0     \n",
            "4 | train_gpt_loss | MeanMetric       | 0     \n",
            "5 | valid_gpt_loss | MeanMetric       | 0     \n",
            "----------------------------------------------------\n",
            "37.8 K    Trainable params\n",
            "0         Non-trainable params\n",
            "37.8 K    Total params\n",
            "0.151     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logger.version = 53\n",
            "                                                                           "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/matvey/.pyenv/versions/3.9.16/envs/ML_project/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|██████████| 188/188 [00:04<00:00, 39.92it/s, loss=2.5, v_num=53, gpt/valid_gpt_loss=2.490, gpt/valid_f1_weighted=0.234] \n",
            "{'gpt/loss': tensor(2.4726), 'gpt/valid_gpt_loss': tensor(2.4926), 'gpt/valid_f1_weighted': tensor(0.2341, dtype=torch.float64), 'gpt/train_gpt_loss': tensor(2.5084)}\n"
          ]
        }
      ],
      "source": [
        "print(f'logger.version = {trainer.logger.version}')\n",
        "trainer.fit(model_downstream, train_dl)\n",
        "print(trainer.logged_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "89598345",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/home/matvey/.pyenv/versions/3.9.16/envs/ML_project/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing DataLoader 0: 100%|██████████| 47/47 [00:02<00:00, 23.22it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "  gpt/test_f1_weighted      0.23819629691443897\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'gpt/test_f1_weighted': 0.23819629691443897}]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.test(model_downstream, train_dl)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "df390a86",
      "metadata": {},
      "source": [
        "## Embedding training (contrastive)\n",
        "\n",
        "### Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "79274426",
      "metadata": {},
      "outputs": [],
      "source": [
        "trx_encoder_params = dict(\n",
        "    embeddings_noise=0.0,\n",
        "    embeddings={\n",
        "        'small_group': {'in': 350, 'out': 16},\n",
        "        'amount_rur_bin':{'in': 11, 'out': 16}\n",
        "    },\n",
        ")\n",
        "\n",
        "seq_encoder = RnnEncoder(\n",
        "        input_size=32,\n",
        "        hidden_size=32,\n",
        "        type='gru',\n",
        ")\n",
        "\n",
        "model = GptPretrainContrastiveModule(\n",
        "    trx_encoder=TrxEncoder(**trx_encoder_params),\n",
        "    seq_encoder=seq_encoder,\n",
        "    max_lr=0.01,\n",
        "    total_steps=10000\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "19835f90",
      "metadata": {},
      "source": [
        "### Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "f86c0117",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "trainer = pl.Trainer(\n",
        "    max_epochs=100,\n",
        "    gpus=1 if torch.cuda.is_available() else 0,\n",
        "    callbacks=[pl.callbacks.EarlyStopping('mlm/valid_mlm_loss')],\n",
        "    enable_progress_bar=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "408038f2",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name            | Type             | Params\n",
            "-----------------------------------------------------\n",
            "0 | trx_encoder     | TrxEncoder       | 5.8 K \n",
            "1 | _seq_encoder    | RnnEncoder       | 6.4 K \n",
            "2 | fn_norm_predict | PBShell          | 0     \n",
            "3 | loss_fn         | QuerySoftmaxLoss | 0     \n",
            "4 | train_mlm_loss  | MeanMetric       | 0     \n",
            "5 | valid_mlm_loss  | MeanMetric       | 0     \n",
            "-----------------------------------------------------\n",
            "12.2 K    Trainable params\n",
            "0         Non-trainable params\n",
            "12.2 K    Total params\n",
            "0.049     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logger.version = 55\n",
            "Epoch 26: 100%|██████████| 188/188 [00:08<00:00, 23.29it/s, loss=0.474, v_num=55, mlm/valid_mlm_loss=0.475]\n",
            "{'mlm/loss': tensor(0.4776), 'mlm/valid_mlm_loss': tensor(0.4752), 'mlm/train_mlm_loss': tensor(0.4753)}\n",
            "CPU times: user 4min 45s, sys: 11.8 s, total: 4min 56s\n",
            "Wall time: 3min 36s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(f'logger.version = {trainer.logger.version}')\n",
        "trainer.fit(model, train_dl)\n",
        "print(trainer.logged_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "6e558f25",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_downstream = NextItemPredictionModule(\n",
        "    trx_encoder=model.trx_encoder, #TrxEncoder(**trx_encoder_params),\n",
        "    seq_encoder=model._seq_encoder, # seq_encoder,\n",
        "    target_col='small_group',\n",
        "    max_lr=0.1,\n",
        "    total_steps=10000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "bbddfe97",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "trainer = pl.Trainer(\n",
        "    max_epochs=100,\n",
        "    gpus=1 if torch.cuda.is_available() else 0,\n",
        "    callbacks=[pl.callbacks.EarlyStopping('gpt/valid_f1_weighted', mode='max', patience=5)],\n",
        "    enable_progress_bar=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "74eb368f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name           | Type             | Params\n",
            "----------------------------------------------------\n",
            "0 | trx_encoder    | TrxEncoder       | 5.8 K \n",
            "1 | _seq_encoder   | RnnEncoder       | 6.4 K \n",
            "2 | head           | Head             | 24.9 K\n",
            "3 | loss           | CrossEntropyLoss | 0     \n",
            "4 | train_gpt_loss | MeanMetric       | 0     \n",
            "5 | valid_gpt_loss | MeanMetric       | 0     \n",
            "----------------------------------------------------\n",
            "37.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "37.0 K    Total params\n",
            "0.148     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logger.version = 60\n",
            "                                                                           "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/matvey/.pyenv/versions/3.9.16/envs/ML_project/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "/home/matvey/.pyenv/versions/3.9.16/envs/ML_project/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 188/188 [00:04<00:00, 39.86it/s, loss=2.85, v_num=60, gpt/valid_gpt_loss=2.870, gpt/valid_f1_weighted=0.142]\n",
            "{'gpt/loss': tensor(2.8486), 'gpt/valid_gpt_loss': tensor(2.8665), 'gpt/valid_f1_weighted': tensor(0.1418, dtype=torch.float64), 'gpt/train_gpt_loss': tensor(2.8642)}\n"
          ]
        }
      ],
      "source": [
        "print(f'logger.version = {trainer.logger.version}')\n",
        "trainer.fit(model_downstream, train_dl)\n",
        "print(trainer.logged_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "ad75a6f3",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/home/matvey/.pyenv/versions/3.9.16/envs/ML_project/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing DataLoader 0: 100%|██████████| 47/47 [00:01<00:00, 27.23it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "  gpt/test_f1_weighted      0.14532649462306496\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'gpt/test_f1_weighted': 0.14532649462306496}]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.test(model_downstream, train_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "988c508d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-04T18:12:30.169403Z",
          "iopub.status.busy": "2022-05-04T18:12:30.168916Z",
          "iopub.status.idle": "2022-05-04T18:12:30.240250Z",
          "shell.execute_reply": "2022-05-04T18:12:30.239734Z"
        },
        "id": "988c508d"
      },
      "outputs": [],
      "source": [
        "from ptls.frames.bert import MLMPretrainModule\n",
        "from ptls.nn import TrxEncoder, RnnEncoder\n",
        "# from ptls.frames.gpt import GptPretrainModule\n",
        "\n",
        "\n",
        "# trx_encoder_params = dict(\n",
        "#     embeddings_noise=0.0,\n",
        "#     # numeric_values={'amount_rur': 'identity'},\n",
        "#     embeddings={\n",
        "#         # 'trans_date': {'in': 800, 'out': 16},\n",
        "#         'small_group': {'in': 350, 'out': 32},\n",
        "#         # 'amount_rur':{'in': 50, 'out': 16}\n",
        "#     },\n",
        "# )\n",
        "\n",
        "trx_encoder_params = dict(\n",
        "    embeddings_noise=0.0,\n",
        "    embeddings={\n",
        "        'small_group': {'in': 350, 'out': 16},\n",
        "        'amount_rur_bin':{'in': 60, 'out': 16}\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "seq_encoder = RnnEncoder(\n",
        "        input_size=32,\n",
        "        hidden_size=32,\n",
        "        type='gru',\n",
        ")\n",
        "\n",
        "# model = GptPretrainModule(\n",
        "#     trx_encoder=TrxEncoder(**trx_encoder_params),\n",
        "#     seq_encoder=seq_encoder,\n",
        "#  #   loss_type='contrast'\n",
        "# )\n",
        "\n",
        "# model = GptPretrainContrastiveModule(\n",
        "#     trx_encoder=TrxEncoder(**trx_encoder_params),\n",
        "#     seq_encoder=seq_encoder,\n",
        "#     max_lr=0.01,\n",
        "#     total_steps=10000\n",
        "# )\n",
        "\n",
        "model = MLMPretrainModule(\n",
        "    trx_encoder=TrxEncoder(**trx_encoder_params),\n",
        "    seq_encoder=seq_encoder,\n",
        "    total_steps=30000,\n",
        "    max_lr=1,\n",
        "    neg_count=5,\n",
        "    replace_proba=0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87997ac0",
      "metadata": {
        "id": "87997ac0"
      },
      "source": [
        "### Data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "624065bf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-04T18:12:30.244098Z",
          "iopub.status.busy": "2022-05-04T18:12:30.243491Z",
          "iopub.status.idle": "2022-05-04T18:12:30.281553Z",
          "shell.execute_reply": "2022-05-04T18:12:30.281940Z"
        },
        "id": "624065bf"
      },
      "outputs": [],
      "source": [
        "from ptls.data_load.datasets import MemoryMapDataset\n",
        "from ptls.data_load.iterable_processing import SeqLenFilter\n",
        "from ptls.frames.gpt import GptDataset\n",
        "from ptls.frames.bert import MlmDataset\n",
        "from ptls.frames import PtlsDataModule\n",
        "\n",
        "\n",
        "# train_dl = PtlsDataModule(\n",
        "#     train_data=GptDataset(\n",
        "#         MemoryMapDataset(\n",
        "#             data=train,\n",
        "#             # i_filters=[\n",
        "#             #     SeqLenFilter(min_seq_len=25),\n",
        "#             # ],\n",
        "#         ),\n",
        "#         min_len=25, \n",
        "#         max_len=300\n",
        "#     ),\n",
        "#     valid_data=GptDataset(\n",
        "#         MemoryMapDataset(\n",
        "#             data=test,\n",
        "#             # i_filters=[\n",
        "#             #     SeqLenFilter(min_seq_len=25),\n",
        "#             # ],\n",
        "#         ),\n",
        "#         min_len=25, \n",
        "#         max_len=300\n",
        "#     ),\n",
        "#     train_batch_size=128,\n",
        "# )\n",
        "\n",
        "train_dl = PtlsDataModule(\n",
        "    train_data=MlmDataset(\n",
        "        MemoryMapDataset(\n",
        "            data=train,\n",
        "            i_filters=[\n",
        "                SeqLenFilter(min_seq_len=25),\n",
        "            ],\n",
        "        ),\n",
        "        min_len=25, \n",
        "        max_len=300\n",
        "    ),\n",
        "    valid_data=MlmDataset(\n",
        "        MemoryMapDataset(\n",
        "            data=test,\n",
        "            i_filters=[\n",
        "                SeqLenFilter(min_seq_len=25),\n",
        "            ],\n",
        "        ),\n",
        "        min_len=25, \n",
        "        max_len=300\n",
        "    ),\n",
        "    train_batch_size=64,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc9a09be",
      "metadata": {
        "id": "fc9a09be"
      },
      "source": [
        "### Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "8fdbb67d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-05-04T18:12:30.285432Z",
          "iopub.status.busy": "2022-05-04T18:12:30.284949Z",
          "iopub.status.idle": "2022-05-04T18:12:30.325745Z",
          "shell.execute_reply": "2022-05-04T18:12:30.325312Z"
        },
        "id": "8fdbb67d",
        "outputId": "c39d04da-3688-4ad9-e8c4-2a129545f701"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import logging\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=100,\n",
        "    gpus=1 if torch.cuda.is_available() else 0,\n",
        "    enable_progress_bar=True,\n",
        "    accelerator='gpu'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a88078a3",
      "metadata": {
        "id": "a88078a3"
      },
      "source": [
        "### Training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "f40877df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451,
          "referenced_widgets": [
            "4088def909e74f22bcc436cc085258eb",
            "13b81a84efd14fbca304ef954cc6cd52",
            "b51eba065e59489c8e10277644661b26",
            "f5ac443da88b4bbd965d956c4274cf26",
            "285efa1b04ef48a2bd5f68f4bddd6726",
            "51eade651ea94b269a4c50c6617c555f",
            "a99f18b281484db4830eb727313e1d5f",
            "dd49373af6d841b8a013ced02d75818b",
            "276448eb91ce45e8ba71d3af80a6425c",
            "a46a71f7b9ee4207813dd7ea4604ae86",
            "ba82e6d3825144c9b92c945b757ffa49"
          ]
        },
        "execution": {
          "iopub.execute_input": "2022-05-04T18:12:30.328969Z",
          "iopub.status.busy": "2022-05-04T18:12:30.328486Z",
          "iopub.status.idle": "2022-05-04T18:23:09.969669Z",
          "shell.execute_reply": "2022-05-04T18:23:09.969186Z"
        },
        "id": "f40877df",
        "outputId": "26fdf0b9-e357-44ac-e990-55efeb3b0078"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name            | Type             | Params\n",
            "-----------------------------------------------------\n",
            "0 | trx_encoder     | TrxEncoder       | 6.6 K \n",
            "1 | _seq_encoder    | RnnEncoder       | 6.4 K \n",
            "2 | fn_norm_predict | PBShell          | 0     \n",
            "3 | loss_fn         | QuerySoftmaxLoss | 0     \n",
            "4 | train_mlm_loss  | MeanMetric       | 0     \n",
            "5 | valid_mlm_loss  | MeanMetric       | 0     \n",
            "-----------------------------------------------------\n",
            "13.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.0 K    Total params\n",
            "0.052     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logger.version = 61\n",
            "                                                                           "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/matvey/.pyenv/versions/3.9.16/envs/ML_project/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "/home/matvey/.pyenv/versions/3.9.16/envs/ML_project/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3:  47%|████▋     | 185/394 [00:04<00:04, 42.83it/s, loss=nan, v_num=61, mlm/valid_mlm_loss=1.640] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/matvey/.pyenv/versions/3.9.16/envs/ML_project/lib/python3.9/site-packages/torchmetrics/aggregation.py:77: UserWarning: Encounted `nan` values in tensor. Will be removed.\n",
            "  warnings.warn(\"Encounted `nan` values in tensor. Will be removed.\", UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58:  52%|█████▏    | 204/394 [00:04<00:04, 43.82it/s, loss=nan, v_num=61, mlm/valid_mlm_loss=nan.0]{'mlm/loss': tensor(nan, device='cuda:0'), 'mlm/valid_mlm_loss': tensor(nan, device='cuda:0'), 'mlm/train_mlm_loss': tensor(nan, device='cuda:0')}\n",
            "CPU times: user 7min 48s, sys: 56.2 s, total: 8min 44s\n",
            "Wall time: 8min 16s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/matvey/.pyenv/versions/3.9.16/envs/ML_project/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58:  52%|█████▏    | 204/394 [00:18<00:17, 10.91it/s, loss=nan, v_num=61, mlm/valid_mlm_loss=nan.0]"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(f'logger.version = {trainer.logger.version}')\n",
        "trainer.fit(model, train_dl)\n",
        "print(trainer.logged_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aaa35bc",
      "metadata": {
        "id": "7aaa35bc"
      },
      "source": [
        "### Save sequence encoder for other experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6d4c390",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50b76d62",
      "metadata": {
        "id": "50b76d62"
      },
      "outputs": [],
      "source": [
        "torch.save(seq_encoder.state_dict(), \"coles-emb.pt\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13b81a84efd14fbca304ef954cc6cd52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51eade651ea94b269a4c50c6617c555f",
            "placeholder": "​",
            "style": "IPY_MODEL_a99f18b281484db4830eb727313e1d5f",
            "value": "Epoch 13:  57%"
          }
        },
        "276448eb91ce45e8ba71d3af80a6425c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "285efa1b04ef48a2bd5f68f4bddd6726": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "4088def909e74f22bcc436cc085258eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13b81a84efd14fbca304ef954cc6cd52",
              "IPY_MODEL_b51eba065e59489c8e10277644661b26",
              "IPY_MODEL_f5ac443da88b4bbd965d956c4274cf26"
            ],
            "layout": "IPY_MODEL_285efa1b04ef48a2bd5f68f4bddd6726"
          }
        },
        "51eade651ea94b269a4c50c6617c555f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a46a71f7b9ee4207813dd7ea4604ae86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a99f18b281484db4830eb727313e1d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b51eba065e59489c8e10277644661b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd49373af6d841b8a013ced02d75818b",
            "max": 94,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_276448eb91ce45e8ba71d3af80a6425c",
            "value": 54
          }
        },
        "ba82e6d3825144c9b92c945b757ffa49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd49373af6d841b8a013ced02d75818b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5ac443da88b4bbd965d956c4274cf26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a46a71f7b9ee4207813dd7ea4604ae86",
            "placeholder": "​",
            "style": "IPY_MODEL_ba82e6d3825144c9b92c945b757ffa49",
            "value": " 54/94 [01:07&lt;00:50,  1.26s/it, loss=12.1, v_num=3]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
